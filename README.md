# 5tech-ASR

A lightweight Automatic Speech Recognition (ASR) system designed for fine-tuning and inference using custom datasets.

## üì¶ Installation

Clone the repository:

```bash
git clone https://github.com/us-inc/5tech-ASR.git
cd 5tech-ASR
```

## üóÇ Dataset Preparation

Prepare your dataset for training:

### üìÑ Dataset Format

Your dataset **must** include the following two mandatory columns:

- `audio`: Path to the audio file or the audio data itself.
- `transcription`: The corresponding text transcription for the audio.

Make sure all audio files are accessible and properly formatted before running the script.

#### Example format (CSV or JSON):

| audio               | transcription                      |
|---------------------|------------------------------------|
| audio/001.wav       | Hello, how can I help you today?   |
| audio/002.wav       | Please take a deep breath.         |

> ‚ö†Ô∏è Note: If using Hugging Face datasets, ensure the dataset you reference includes these two fields.

This step will preprocess and organize the audio-text pairs for training.

```bash
python prepare_dataset.py --dataset_name jarvisx17/Medical-ASR-EN --split train --data_dir ./datasets
```

## üñ® Output Example:

```bash
Loading dataset 'jarvisx17/Medical-ASR-EN' split 'train'...
Loaded 6661 samples.
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6661/6661 [01:05<00:00, 101.62it/s]

Total duration: 8.47 hours
Manifest created at: ./datasets/jarvisx17_Medical-ASR-EN/train_manifest.json

```

## üß† Training

Start the model training process:

```bash
chmod +x run_train.sh
./run_train.sh
```

This script will initiate fine-tuning of the ASR model using the processed dataset.

## üîç Inference

Run inference on new audio files:

```bash
python inference.py \
  --checkpoint canary_results/nvidia_canary-1b-flash-finetune/checkpoints/nvidia_canary-1b-flash-finetune.nemo \
  --audio datasets/jarvisx17_Medical-ASR-EN/audio/sample_990.wav

```

This will output the transcriptions for the input audio using the trained ASR model.

## üìÅ Project Structure

```
5tech-ASR/
‚îú‚îÄ‚îÄ dataset.py         # Prepares and processes the dataset
‚îú‚îÄ‚îÄ train.py           # Trains the ASR model
‚îú‚îÄ‚îÄ inference.py       # Runs inference using the trained model
‚îú‚îÄ‚îÄ utils/             # Utility functions (if available)
‚îî‚îÄ‚îÄ models/            # Model definitions (if available)
```

## üõ† Requirements

Make sure to install required dependencies. You can create a `requirements.txt` file or install manually:

```bash
pip install -r requirements.txt
```

## üì¨ Contact

For questions or contributions, feel free to open an issue or pull request.
